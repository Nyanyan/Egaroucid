# Egaroucid 技術資料

**ここに書いた内容は高度なものです。一般的なアルゴリズムの話はしません。オセロAI初心者向け記事は[こちら](https://note.com/nyanyan_cubetech/m/m54104c8d2f12)に書きました。**

このページは日本語のみで、のんびりと気が向いたときに書き足していきます。



## minimaxかMCTSか

ゲームAIを作る上でのアルゴリズムは古くからminimax法が有名でした。1997年にチェスで人間を打ち負かしたDeep Blueも、同年にオセロで人間を打ち負かしたLogistelloも、このminimax法から派生するアルゴリズムでした。しかし、2000年に入るとMCTS(モンテカルロ木探索)が発展し、さらに2010年代にはMCTSをさらにアップデートしたPV-MCTS (Policy Value MCTS)が発展しました。2016年に囲碁で人間を打ち負かしたAlphaGoはPV-MCTSです。

この2つのアルゴリズムは根本から違うものです。将棋AIでは聞くところによるとすでにPV-MCTS優勢(2022年現在の伝聞)だそうですが、オセロにおいてはどちらを使うのが良いでしょうか。

オセロにおいてminimax系統が良いのかMCTS系統が良いのかは、まだ断言できないと思います。ですが、私はEgaroucidに対してminimax法から派生したNegascout法を利用しました。この理由について、軽くまとめます。



**オセロでは精度の高い評価関数を簡単に作れるから**

minimax法では、計算量の問題で終局まで読みきれない場合には終局前に評価関数を使って、それをそのまま終局まで読んだ確定値と同じように利用します。つまり、評価関数の精度が悪ければ必然的にAIは弱くなります。

囲碁では評価関数が作りにくいようで、そのために評価関数を使わなくて済むMCTSが発展したそうです。

オセロにおいては、Logistelloに関する論文「Experiments with Multi-ProbCut and a New High-Quality Evaluation Function for Othello」でパターンを用いた評価関数が提案されてから、(それなりに)手軽に高精度の評価関数が作れるようになりました。ですので、この方法を踏襲すれば良かったわけです。

**オセロは合法手数が比較的少ないから**

MCTSは評価関数を必要としない以外にも利点があります。それは、合法手が多いゲームでもそれなりの性能が出せるところです。オセロは局面1つに対して概ね10手前後の合法手しかありませんが、例えば囲碁はとんでもないことになります。

各局面の合法手数をb、探索する深さをdとすると、minimax法の計算量はb^d、そしてminimax法に効果的な枝刈りを施したαβ法はsqrt(b^d)です。これでは、合法手が多いゲームでは計算量が爆発しやすくなって困ります。

しかし、オセロに関して言えばこの問題はそこまで大きくありません。



## 評価関数

既存の強豪オセロAIに広く使われているパターン評価は、Logistelloで提案され、今日のEdaxまでほとんど形を変えずに受け継がれています。Egaroucidもこのパターン評価をベースにしていますが、少し特徴量を追加しました。

盤面のパターンとして使ったのは以下です。







## 中盤探索



## 終盤探索



## CPUでの並列化

